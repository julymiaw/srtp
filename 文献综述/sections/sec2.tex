\section{基于向量空间的方法}
Buglocator\cite{6227210}使用向量空间模型（rVSM）根据bug报告和源代码之间的文本相似性对所有文件进行排名，同时考虑之前已修复的相似bug的信息。

同一时期的BLUiR\cite{6693093}充分利用了代码结构信息，引入抽象语法树(AST)以保存更多的结构信息，同时丢弃了语言标识符，让模型能在保留代码结构信息的同时关注语句间关联。

后续研究开始将以上思路拓展到其他错误定位任务中，如Sahu等\cite{6976082}尝试在非面向对象的编程语言如C上使用该方法(此前研究均基于Java语言)，发现Buglocator依然有效，但引入代码结构信息的效果有限。这或许表明面向对象编程语言的结构信息对错误定位更为有效。

Le等\cite{6982639}使用支持向量机(SVM)构建了一个预测模型来评估该方法的有效性。当方法如Buglocator生成的可疑度排名不可靠时，该方法可以提醒研究人员及时改用传统调试方法。

2014年，Hill等人\cite{6747185}进一步探索了邻近位置信息在静态错误定位中的应用。该方法使用马尔可夫随机场（MRF）构建依赖关系图来对检索的项间依赖关系进行建模，并使用Software Word Usage Model(SWUM)\cite{hill2010integrating}提取错误报告中的短语概念(phrasal concepts)。

2016年，MULAB\cite{7816459}将VSM扩展为MULti-ABstraction VSM以考虑多抽象级别(即同一单词在不同语境下的不同含义)，并使用adaptive LDA和遗传算法(LDA-GA)来调整每个抽象级别的主题号。

2019年，Liu等\cite{8736209}的研究将词嵌入方法引入向量空间方法，这是2016年词嵌入被用于软件工程领域开始，首次将其引入错误定位。Amasaki等\cite{8906763}比较了多种向量化方法，从Buglocator使用的tf-idf方法开始，到其他tf-idf方法和Word2Vec方法。该研究采用了Bench4Bl提供的评估框架。

2021年，WEQE\cite{9700273}采用了自动查询扩展(AQE)，这项技术依赖首次检索时使用的查询质量，故采用单词嵌入技术来识别初始查询中的语义关键词。
\section{基于学习排名的方法}
学习排名(Learning to Rank)是一种机器学习技术，2014年Ye等人\cite{10.1145/2635868.2635874}首次将学习排名(LR)技术引入静态错误定位，并构建了一个更大的基准数据集，后续研究往往均会根据此基准数据集评估方法有效性。此外，该方法首次使用Top K，MAP和MRR作为衡量指标，这也成为了后续方法的常用指标。LR技术在6个Java项目上的表现均超越了Buglocator。

然而，\cite{7272945}发现LR技术的效果与标准的向量空间模型(VSM)类似，且在Top k指标上更差。向量空间模型首先把代码和错误报告映射到向量空间，再计算余弦相似度，这种方法利用的信息更少且同样有效。后续研究在相关性的评估上多沿用VSM方法，但向量化的方式各不相同。
\section{基于代码修改历史的方法}
2015年开始，研究人员开始尝试使用代码修改历史来提高错误定位的效果。BLIA\cite{7467300}使用代码修改历史来改进IRFL方法，发现代码修改历史可以提高错误定位的准确性。这一发现在后续研究中得到了证实，如Locus\cite{7582764}利用错误报告与更改日志中包含的信息之间的相关性提升了基于VSM的静态错误定位方法方法的性能。

Bugpecker\cite{9286037}通过代码修订图来跟踪代码修改历史，同时采用了抽象语法树来处理代码结构信息。2021年，MRAM\cite{9462960}结合了循环神经网络(RNN)，注意力模型和多层感知机(MLP)，解决了原先方法无法弥合语义差距，无法充分利用历史修改信息的问题。该方法同样使用代码修订图来揭示函数间关系，且由于引入了Attention机制，可以更好地处理上下文信息。这两种方法均采用了Ye等人创建的基准数据集。
\section{基于执行信息的方法}
不断有研究尝试结合动态方法来提高静态方法的定位效果，常见的执行信息包括覆盖率、切片和频谱，\cite{7961521}把这些执行信息应用到Buglocator和BLUiR等经典的静态错误定位方法中，发现仅添加覆盖信息就大大提高了这些技术整体有效性，其中在类(class)级别对BLUiR方法的提升最为显著，而切片信息进一步提高了效果，频谱信息在函数级别显著提高了定位效果，但在类级别提升有限。
\section{基于深度学习的方法}
2017年起，人们开始思考如何更好地使用深度神经网络表示代码语言\cite{10.1145/3106237.3106290}。Chen\cite{10062428}等人采用了对抗神经网络的思想，比单一使用CNN等神经网络的方法效果更好。

2020年一篇名为《Attention is All You Need》\cite{NIPS2017_3f5ee243}的论文提出了Transformer模型，这一模型在自然语言处理领域取得了巨大成功(如Bert，GPT等自然语言模型)，因为它可以更好地处理上下文语境。在这之后，Transformer开始成为深度神经网络的代名词，该技术在各方面超越了CNN，RNN等传统神经网络，在处理长文本上也有较好的效果。同样在2020年，代码搜索领域的方法开始被应用于错误定位\cite{9462960}\cite{Liang2022}，因为代码搜索领域同样需要弥合自然语言和代码语言间的语义差距。

2021年，DeepFL\cite{9653844}将Transformer技术应用到错误定位中，这是第一个将该技术应用于即时行级缺陷定位任务的模型，可以做到在第一时间准确定位错误。该方法采用Seq2Seq结构，包含编码器和解码器，其输入和输出均为代码语言，输出的代码语言是更“干净”\cite{6227135}的。当输入一个包含缺陷代码的错误报告时，模型会计算每一行代码及其周围代码与“干净”代码的差距，差距即为可疑度分数。该方法是最先进的基于深度学习的错误定位方法之一，且已开放数据集。

2022年，FLIM\cite{Liang2022}借用了自然语言处理领域常见的先预训练后微调形式，采用了CodeBERT\cite{2020CodeBERT}这一预训练模型。实际上，CodeBERT已经在代码搜索领域取得了巨大成功，因为大模型可以更好地弥合自然语言和代码语言间的语义差距。FLIM同时采用了LR学习排名技术来进一步处理预训练模型的输出，生成可疑度排名。
\section{其他方法}
\cite{8973028}首次采用代码异味检测技术改进静态错误定位，该方法使用了两种成熟的技术进行结合，效果提升明显。

BoostNSift\cite{9610655}没有采用额外的信息输入，但在Buglocator的数据集上达到了Buglocator和BLUiR近3倍的性能。与Buglocator等采用的tf-idf向量化技术不同，该方法采用了更符合直觉的BM25。BM25对相关性更敏感，对较长和较短的函数有着更好的处理能力。该方法的最大特点是文本提升技术，先对错误报告和代码分别进行提升，再进行搜索。该方法如果与其他方法进行混合，可能会产生更好的效果。该方法已开放数据集，数据集包含Buglocator与Ye等人的数据集。
\section{数据集选取}
2018年，\cite{8449523}发现此前许多研究的数据集是无效的，因为这些数据集将测试文件包含在了数据集中，这可能会导致评分虚高。在去除了测试文件后，Buglocator依旧有效，但是BLUiR的MAP评分和MRR评分均明显下降，这可能意味着之前大量研究中，BLUiR方法的效果被高估了。

同一年，\cite{10.1145/3213846.3213856}反驳了上述看法，认为无须去除测试文件，并给出了一个完整的评估框架Bench4BL。后续的大量研究都采用了这个评估框架。

Rahman等\cite{10.1145/3183440.3195003}探索了数据集中错误报告的代码含量对静态错误定位方法的影响。具体来说，他们选择了采用BugZilla或JIRA错误管理系统的项目，构建了仅包含自然语言的错误报告数据集和含有大量代码描述的错误报告数据集，发现缺少代码信息和过多代码信息都会降低定位工具的性能。

Zhang等\cite{https://doi.org/10.1002/smr.2312}重点关注了深度学习数据集的平衡问题，他们认为，要学习代码的特征，需要正确和错误代码的数量达到平衡，否则模型会倾向于学习错误代码的特征。他们提出了一种重采样技术，可以改善数据集不平衡问题。