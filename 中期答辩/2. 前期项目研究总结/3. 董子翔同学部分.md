### GraphCodeBert

GraphCodeBERT模型没有考虑抽象语法树，而是采用了DFG（数据流向图）。数据流向图是一个有向图，代表了每个变量的值从哪里来到哪里去的关系。

为了显示GraphCodeBERT的有效性，作者进行了四项下游任务，包括了代码搜索、克隆检测、代码翻译和代码改错。而我们所需要的是对源代码的定位，故侧重于代码搜索。[^1]

代码搜索的任务是通过输入一段自然语言描述，模型输出从代码库中选出一段最符合描述的代码。

该模型首先按照下列方式将过滤数据集以提高质量（$utils.py$）

* 删除代码中的注释
* 删除无法将代码解析为抽象语法树的示例。
* 删除文档 #tokens 为 < 3 或 >256 的示例
* 删除文档包含特殊标记的示例（例如 <img ...> 或 https：...）
* 删除文档不是英文的示例。

最后经过实验发现该模型实现了最先进的性能。

该模型首先将数据集生成对应语言的DFG ($DFG.py$)，再将代码转换为特征，用于训练机器学习模型，最后训练模型并对模型进行评估，打印评估结果。

该模型的主要创新点便是DFG，例如：
```python
def bubble_sort(lst):
    '''
    Sorts a list of integers using bubble sort.
    '''
    n = len(lst)
    for i in range(n):
        for j in range(0, n-i-1):
            if lst[j] > lst[j+1] :
                lst[j], lst[j+1] = lst[j+1], lst[j]
    return lst
```
经过testDemo.ipynb处理后得到数据集，我们需要的部分为original_string和docstring_tokens部分。
```python
original_string部分：
def bubble_sort(lst):\n    n = len(lst)\n    for i in range(n):\n        for j in range(0, n-i-1):\n            if lst[j] > lst[j+1] :\n                lst[j], lst[j+1] = lst[j+1], lst[j]\n    return lst\n

docstring_tokens部分：
["Sorts", "a", "list", "of", "integers", "using", "bubble", "sort", "."]
```
首先逐个记录出现的变量，并用左闭右开的集合保存入dfg_to_code，再根据这个变量由哪些变量得到绘制出dfg_to_dfg

[^1]:GRAPHCODEBERT: PRE-TRAINING CODE REPRESENTATIONS WITH DATA FLOW (Published as a conference paper at ICLR 2021)
