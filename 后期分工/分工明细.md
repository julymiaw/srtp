# 暑假工作分工

考虑到以往的任务完成情况，本次作出以下调整。

首先，时间上分为三个阶段，从今天开始到7月9号为第一阶段，7月9号到8月19号为第二阶段，8月19号到9月15号为第三阶段。

据我目前了解，7月9号前，除我和万奕含同学在校参加数模国赛培训外，其余3名同学已正常回家。因此第一阶段任务主要由回家的3名同学完成。

7月9日左右开一次线上组会，为保证项目按期完成，如果有同学负责部分的进度缓慢，可将部分任务转交给我和万奕含同学，这不影响最后的分数分配。

8月19日开始为暑期学校，鉴于一开学就要筹备结项工作，这是项目推进的最后机会，我们线下再开一次组会，如果到这时有同学负责部分的进度仍旧缓慢，将由我或完成进度较快的同学接手，这将直接影响分数分配。

|      时间       | 天数 |                  事件                  |
| :-------------: | :--: | :------------------------------------: |
|     6月22日     |  ——  |     线上组会，明确分工及阶段性要求     |
| 6月22日-7月9日  | 17天 |        3名组员根据分工开始工作         |
|     7月9日      |  ——  |   线上组会，大家展示进度，可调整分工   |
| 7月9日-8月19日  | 41天 | 所有人员开始工作，以完成所有任务为目标 |
|     8月19日     |  ——  |      线下组会，展示进度，调整分工      |
| 8月19日-9月15日 | 27天 |          保证所有任务按期完成          |

这里，再回顾一下总分数的可能情况。鉴于中期答辩的评分不影响结题答辩的评分，我们仍有机会获得良好以上的评分。

| 结题评分 | 项目基本分 | 项目附加分 | 人均分值 | 个人得分上限 |
| :------: | :--------: | :--------: | :------: | :----------: |
|   优秀   |    9.0     |    3.0     |   2.4    |     3.0      |
|   良好   |    7.0     |    3.0     |   2.0    |     2.5      |
|   通过   |    4.4     |    3.0     |   1.5    |     2.0      |
|  不通过  |     0      |     ——     |    ——    |      ——      |

如果因为工作完成较少导致分工调整，会在人均分值的基础上调整，承担较多工作的同学得分不超过学校规定的得分上限。所以，大家还是要团结起来，总评分提高了，大家的得分就都提高了。

关于SRTP分，我想额外补充一下，SRTP分不仅是毕业要求，还在保研推免排名中有较大权重。下图是今年计算机学院的保研排名公示：
![image-20240620114733631](./%E5%88%86%E5%B7%A5%E6%98%8E%E7%BB%86.assets/image-20240620114733631.png)

可以看到，许多绩点排名靠后的同学通过综合能力加分完成了反超，综合能力加分具体见学院政策，我不了解，但我想和SRTP分数还是有一定关联的。

## 工作总览

我们的工作总体上是1个数据集+3个模型，最后的输出是3个模型在那个数据集上的表现，其中，第一个模型的输出应该与此前那篇论文的结论相似，后两个模型的输出应该比第一个模型更好，如果没有变得更好，需要找到原因。

此前，在中期答辩前，我们已经大致完成了数据集的搭建，可惜的是没有完成第一个模型的论文结果复现，这其实已经慢于任务书中的计划了，大家必须在暑假中赶上进度。我们还需要发布一篇论文，如果没有及时获得足够的数据，那么论文的发表会非常赶。(学校只要求论文过初审，但至少也要留出1个月)

对于每一个模型，我们需要以类似原论文的评估方法来评估效果，在写文献综述时我发现了其他的常用评估方法，到时候可以酌情采用。

与模型评估有关的分工将在7月9日组会上进行，希望到那时我们已经完成训练了至少一个模型。

| 序号 |                           工作内容                           |    工作阶段    |                             要求                             |
| :--: | :----------------------------------------------------------: | :------------: | :----------------------------------------------------------: |
|  1   | 提取缩小版数据集，用于本地测试。<br />格式须与完整数据集一致，可参考CSN数据集 |    第一阶段    | 明确数据集格式，<br />完成当前数据集格式与<br />原CSN格式的转换代码 |
|  2   |               提取完整版数据集，用于在线训练。               | 第一、第二阶段 |     训练集，测试集和评估集<br />的比值应接近原CSN数据集      |
|  3   | 使用缩小版数据集，通过设置更小的batch_size等超参数，<br />进行本地训练测试 |    第一阶段    |           能输出TensorBoardX曲线<br />（见附录一）           |
|  4   | 使用完整数据集，选择适当的参数和训练轮数，在云计算平台上进行训练 | 第一、第二阶段 |        能用较少的训练时间(省钱)<br />达到较好的损失率        |
|  5   |  对于已训练的模型，使用与原论文相同的方式评估，验证论文结果  |    第二阶段    | 结果与原论文大致相同<br />有明确的训练数据支持，<br />能画出类似的图表(论文用) |
|  6   |                撰写论文，提交审核，争取过初审                |    第三阶段    |     格式和内容上仿照原论文<br />创新点部分我可以找教授谈     |
|  7   |                      整理文件，准备结项                      |    第三阶段    |                             ————                             |

**附录一：TensorBoardX曲线示例：**
![image-20240622040136940](./%E5%88%86%E5%B7%A5%E6%98%8E%E7%BB%86.assets/image-20240622040136940.png)

以CodeBERT为例，完成训练后，目录下会出现runs文件夹以及日志文件，这些文件可被TensorBoardX自动读取。

![image-20240622040559328](./%E5%88%86%E5%B7%A5%E6%98%8E%E7%BB%86.assets/image-20240622040559328.png)

## 具体分工

刚刚在工作总览部分，已详细说明了第一阶段的主要任务。第一阶段的目标是完成3个模型的训练，至少要完成其中一个模型的训练。

3名同学将分别负责原先负责的模型，其中张闻启同学额外负责缩小版数据集的搭建，其他两名同学须协助完成当前数据集格式与<br />原CodeSearchNet数据集格式的转换代码，同时确保代码的简便性与可读性。（也就是说，可尝试修改模型的数据输入部分代码）如果因技术原因难以完成，可以“迂回”一些，先将数据集格式转化为示例输入的格式，再直接使用原始模型的数据输入部分代码。

第二阶段的主要目标是完成对模型的评估，并完成论文撰写与提交。论文的提交审核周期较长，在模型训练期间我们可能就需要开始论文写作。第三个阶段是预留的缓冲，如果有同学没能按时完成，其他同学需要在这个阶段赶上进度。

**附录二：超参数说明**

对于模型的超参数选择，以CodeBERT为例作出说明，以下内容是我根据经验总结，仅供参考。

|            参数            |                             说明                             | 备注 |
| :------------------------: | :----------------------------------------------------------: | :--: |
|         --data_dir         |                          数据集路径                          | 必填 |
|        --model_type        | 三选一：RobertaConfig, <br />RobertaForSequenceClassification, <br />RobertaTokenizer | 必填 |
|    --model_name_or_path    | 填入模型名称时，自动联网下载模型<br />提供模型路径时，目标文件夹下需包含“pytorch_model.bin” | 必填 |
|        --task_name         |           训练任务名称，目前只有一个："codesearch"           | 必填 |
|        --output_dir        | 模型的输出目录，将用于保存模型检查点（一般每训练一轮会保存一次） | 必填 |
|       --config_name        | 预训练模型的配置信息("config.json")所在目录，默认与模型路径相同 | 可选 |
|      --tokenizer_name      | 分词器的名称或路径，默认与模型路径相同。分词器需要3个文件，<br />merges.txt包含了一系列的字符组合规则，用于将单词分解为子词。<br />special_tokens_map.json定义了一些特殊标记。<br />tokenizer_config.json包含分词器的配置信息，此处设最大长度为512。 | 可选 |
|        --cache_dir         | 如果在参数3中给定了模型名称，那么模型将被下载到这里指定的目录下。 | 可选 |
|      --max_seq_length      | 输入序列的最大长度。如果序列长度超过此值，将被截断；<br />如果序列长度小于此值，将被填充。 | 可选 |
|         --do_train         | 是否进行训练。与之后的三个参数相同，该参数只需指明，无须提供值。 | 可选 |
|         --do_eval          |   是否使用提供的原始模型或训练后的模型在评估集上进行评估。   | 可选 |
|        --do_predict        |                   是否在测试集上进行预测。                   | 可选 |
| --evaluate_during_training |             是否在训练的每个记录步骤中进行评估。             | 可选 |
| --do_lower_case              | 如果你使用的是不区分大小写的模型，设置此标志。               | 可选 |
| --per_gpu_train_batch_size   | 每个GPU/CPU的训练批次大小。                                  | 可选 |
| --per_gpu_eval_batch_size    | 每个GPU/CPU的评估批次大小。                                  | 可选 |
| --gradient_accumulation_steps | 在执行反向/更新传递之前累积的更新步骤数。                    | 可选 |
| --learning_rate              | Adam优化器的初始学习率。                                     | 可选 |
| --weight_decay               | 如果我们应用一些，权重衰减。                                 | 可选 |
| --adam_epsilon               | Adam优化器的Epsilon。                                        | 可选 |
| --max_grad_norm              | 最大梯度范数。                                               | 可选 |
| --num_train_epochs           | 执行的总训练周期数。                                         | 可选 |
| --max_steps                  | 如果> 0：设置要执行的总训练步骤数。覆盖num_train_epochs。    | 可选 |
| --warmup_steps               | 在warmup_steps上的线性预热。                                 | 可选 |
| --logging_steps              | 每X更新步骤记录一次。                                        | 可选 |
| --save_steps                 | 每X更新步骤保存一次检查点。                                  | 可选 |
| --eval_all_checkpoints       | 评估所有以模型名称开头并以步骤号结束的检查点。               | 可选 |
| --no_cuda                    | 当可用时避免使用CUDA。                                       | 可选 |
| --overwrite_output_dir       | 覆盖输出目录的内容。                                         | 可选 |
| --overwrite_cache            | 覆盖缓存的训练和评估集。                                     | 可选 |
| --seed                       | 初始化的随机种子。                                           | 可选 |
| --fp16                       | 是否使用16位（混合）精度（通过NVIDIA apex）而不是32位。      | 可选 |
| --fp16_opt_level             | 对于fp16：在[‘O0’, ‘O1’, ‘O2’, 和 ‘O3’]中选择的Apex AMP优化级别。 | 可选 |
| --local_rank                 | 对于分布式训练：local_rank                                   | 可选 |
| --server_ip                  | 用于远程调试。                                               | 可选 |
| --server_port                | 用于远程调试。                                               | 可选 |
| --train_file                 | 训练文件                                                     | 可选 |
| --dev_file                   | 开发文件                                                     | 可选 |
| --test_file                  | 测试文件                                                     | 可选 |
| --pred_model_dir             | 用于预测的模型                                               | 可选 |
| --test_result_dir            | 存储测试结果的路径                                           | 可选 |